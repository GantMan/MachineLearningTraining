{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transfer Truck Identification.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GantMan/MachineLearningTraining/blob/master/Transfer_Truck_Identification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "oMmBcHXX8By_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Transfer learning!\n",
        "\n",
        "![transfer learning](https://cdn-images-1.medium.com/max/1600/1*FfQWL0PFb1FRgFVAUx5NWQ.jpeg)\n",
        "\n",
        "Grab a well trained and weighted model to start.   Then use its well trained feature detection in your *\"new\"* model.\n",
        "\n",
        "Here's an example of what multiple CNN layers can detect and organize into features:\n",
        "\n",
        "![Detect features](https://i.stack.imgur.com/Hl2H6.png)"
      ]
    },
    {
      "metadata": {
        "id": "eZ9elT_ZsK-z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import joblib\n",
        "from keras.preprocessing import image\n",
        "from keras.applications import xception"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kfkWpA8rsYX9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "[Xception](https://arxiv.org/abs/1610.02357) is a very capable pre-trained model created in 2016 by Google.  This is claimed to be better than Google's Inception v3, due to to it's \"depthwise separable convolution.\"  Want to dig into what that means?  [Here's a blog post for you](https://towardsdatascience.com/review-xception-with-depthwise-separable-convolution-better-than-inception-v3-image-dc967dd42568), but otherwise just know it's pretty damn good.\n",
        "\n",
        "[Keras gives us several lovely models we can build from](https://keras.io/applications/):\n",
        "\n",
        "![keras models](https://i.imgur.com/rVn81It.png =600x)"
      ]
    },
    {
      "metadata": {
        "id": "Y0JacLx18spL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.datasets import cifar10\n",
        "# Load data set from CIFAR-10 again\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "\n",
        "# We'll be separating a test set differently this time\n",
        "# So let's combine back in our test data\n",
        "x_train = np.concatenate((x_train, x_test))\n",
        "y_train = np.concatenate((y_train, y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VLpnFADitL2B",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# adjust it so instead it sets all trucks to true and everything else to false\n",
        "# broadcast boolean logic througout dataset\n",
        "y_train = y_train == 9\n",
        "# prepare x to be normalized (between 0 and 1)\n",
        "x_train = x_train.astype('float32')\n",
        "x_train /= 255\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "67bICK209yxA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now we load in Xception.  Thanks Keras!!!\n",
        "\n",
        "Xception minimal size is 71x71, and CIFAR is 32x32, but leaving the input_shape variable size, makes it work for our case.\n",
        "\n",
        "You will need all input images to be the same size.  So if you add an image from outside CIFAR, it will need to be resized to match our feature extractor.\n"
      ]
    },
    {
      "metadata": {
        "id": "_dfLKEyc-ma0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Load the pre-trained neural network to use\n",
        "# as a feature extractor\n",
        "feature_extractor = xception.Xception(\n",
        "    weights='imagenet',\n",
        "    include_top=False\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xXIeKbKr7uWJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let's take a quick look at the wild world of Xception\n"
      ]
    },
    {
      "metadata": {
        "id": "H__UOwMZ70Lp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "feature_extractor.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "51_Bel5a8GQF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let's use Xception to get alllllll the features we can out of our training set.  Technically speaking, the feature_extractor is known as the \"convolutional base.\"  By running our training data through the convolutional base, it pre-chews our training data, so the resulting neural network (though deep) is a great starting point."
      ]
    },
    {
      "metadata": {
        "id": "8tc-n3b2-2W5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "features_x = feature_extractor.predict(x_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9-Plga1vfiVn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "You can store these features so you don't have to re-extract them everytime."
      ]
    },
    {
      "metadata": {
        "id": "EL5hAxCTd8Qa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "joblib.dump(features_x, \"x_train.dat\")\n",
        "joblib.dump(y_train, \"y_train.dat\")\n",
        "\n",
        "# Load anytime with x_train = joblib.load(\"x_train.dat\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CLnIyDUmgm1j",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UDtWFJQi8_xv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "> ## Thoughtful side note\n",
        "Our model expects input from Xception.  Another way we could have handled this, is to add Xception as our first sequential step, like so:\n",
        "\n",
        "> `model.add(feature_extractor)`\n",
        "\n",
        "> #### This would have had two drawbacks:\n",
        "\n",
        "1.  We would not have been able to store our pre-chewed \"x_train.dat\" to speed up iterations on these new layers that we are experimenting with.\n",
        "2. We would have had to have frozen (or partially frozen) our convolutional base from being trained.  Updating the weights of Xception's primary layers would be undoing a significant advantage.  We can lock `feature_extractor` with `feature_extractor.trainable = false`\n",
        "\n",
        "> #### Benefits would have been:\n",
        "\n",
        "1. We could have had a more streamlined model, with less code.\n",
        "2. We could have unfrozen a few layers of Xception (top down) to fine-tune the model.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "tmqntM3beGXY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Flatten(input_shape=features_x.shape[1:]))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation='sigmoid'))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fwLuwK38f6j0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![too soon](https://pbs.twimg.com/media/Dv6XHN2WkAIKWPJ.jpg =600x)\n",
        "\n",
        "\n",
        "And finally Sigmoid for percentage likelyhood.  Sigmoid with 'binary_crossentropy' is code for \"Make very low value outputs close to zero, and high value close to one, thus telling me the likelyhood percentage of my categorization.\"\n",
        "\n",
        "![sigmoid](https://upload.wikimedia.org/wikipedia/commons/thumb/8/88/Logistic-curve.svg/320px-Logistic-curve.svg.png)"
      ]
    },
    {
      "metadata": {
        "id": "yOUmsbhmr7sU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(\"Trainable weights = \" + str(len(model.trainable_weights)))\n",
        "# View some info!\n",
        "print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Q-899rCXgS1n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "  loss ='binary_crossentropy',\n",
        "  optimizer = 'adam',\n",
        "  metrics=['accuracy']\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pTiIFXM6Em03",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# OPTIMIZE!\n",
        "Momentum, weight decay, and so much more.\n",
        "![momentum and decay](https://datascience-enthusiast.com/figures/opt_momentum.png)\n",
        "\n",
        "*SmoooOOoooOOoooOOoth*\n",
        "\n",
        "![smooth](https://media1.tenor.com/images/7591117adda5f9537830a976ada14bd4/tenor.gif?itemid=3484360)\n",
        "\n",
        "![smooth curve](https://i.stack.imgur.com/bcaCP.png)"
      ]
    },
    {
      "metadata": {
        "id": "hn5OtNJ4g335",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "  features_x,\n",
        "  y_train,\n",
        "  validation_split=0.05,\n",
        "  epochs=20,\n",
        "  shuffle=True\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zqqUjVPhmDU8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Let's graph it!**"
      ]
    },
    {
      "metadata": {
        "id": "YnY1xDelmKYd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UtuXsrM7dteX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Validation lets us identify overfitting, and thusly we can expect poor generalization!\n",
        "\n",
        "**Overfitting looks like this:**\n",
        "\n",
        "![overfit data](https://i.imgur.com/CR3sdQj.png)\n",
        "\n",
        "## What can we do?\n",
        "\n",
        "*   **Early Stop**\n",
        "*   **More training data / Data augmentation**\n",
        "*   **Regularization**\n",
        "*   **Use bigger images**\n",
        "*   **Fine-tune conv base**\n",
        "\n",
        "There are lots of ways to make sure your trained model is a well trained model.  Awesome data means an awesome model.\n",
        "\n",
        "![l2](https://pbs.twimg.com/media/DrqbthQVAAAEaWj.jpg =350x)\n"
      ]
    },
    {
      "metadata": {
        "id": "PDIVhOgDhHPB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Save it for later\n",
        "model.save(\"truck_feature_classifier_model.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lNdgqoCSi3SB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The accuracy is lower than expected with 20 epochs, but faster to train!\n",
        "\n",
        "We now have a model that can use with any image, solong as we extract the features from it first!\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "ZGmgQzMghxO-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import urllib.request\n",
        "from IPython.core.display import Image, display\n",
        "\n",
        "\n",
        "urllib.request.urlretrieve (\"https://www.cs.toronto.edu/~kriz/cifar-10-sample/truck3.png\", \"truck.png\")\n",
        "urllib.request.urlretrieve (\"https://www.cs.toronto.edu/~kriz/cifar-10-sample/bird8.png\", \"not_truck.png\")\n",
        "\n",
        "# Show and tell\n",
        "print('Here are my 2 images to test!')\n",
        "display(Image(\"not_truck.png\"))\n",
        "display(Image(\"truck.png\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1NYodaJBCVYk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# load and convert to numpy arrays\n",
        "truck_img = image.img_to_array(image.load_img(\"truck.png\"))\n",
        "not_truck_img = image.img_to_array(image.load_img(\"not_truck.png\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lyXKjBj2DK-e",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# add fourth dimension to all images (Keras expects bunch of images, not single)\n",
        "truck_img = np.expand_dims(truck_img, axis=0)\n",
        "not_truck_img = np.expand_dims(not_truck_img, axis=0)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YzUwJuICDokA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "truck_img = xception.preprocess_input(truck_img)\n",
        "not_truck_img = xception.preprocess_input(not_truck_img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "68xKiSQpD27Y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "truck_features = feature_extractor.predict(truck_img)\n",
        "not_truck_features = feature_extractor.predict(not_truck_img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GPmAY2RCET7L",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "truck_result = model.predict(truck_features)[0][0]\n",
        "not_truck_result = model.predict(not_truck_features)[0][0]\n",
        "\n",
        "print('truck.png : {:0.2f}% chance of truck'.format(truck_result * 100))\n",
        "print('not_truck.png : {:0.2f}% chance of truck'.format(not_truck_result * 100))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ufGQhvjAx9ZG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "What about some other truck out of the wild?  Like this one from a Google search?!\n",
        "\n",
        "![truck](https://media.wired.com/photos/5b9c3d5e7d9d332cf364ad66/master/pass/AV-Trucks-187479297.jpg =600x)\n",
        "\n",
        "**Let's grab this one and try it on!**"
      ]
    },
    {
      "metadata": {
        "id": "ZQ88rQDaFaSH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "urllib.request.urlretrieve (\"https://media.wired.com/photos/5b9c3d5e7d9d332cf364ad66/master/pass/AV-Trucks-187479297.jpg\", \"internet_truck.png\")\n",
        "# Resize image to 32x32 so the featureset size matches what our model expects as input!\n",
        "internet_truck = image.img_to_array(image.load_img(\"internet_truck.png\", target_size=(32, 32)))\n",
        "internet_truck = np.expand_dims(internet_truck, axis=0)\n",
        "internet_truck = xception.preprocess_input(internet_truck)\n",
        "internet_truck_features = feature_extractor.predict(internet_truck)\n",
        "print(internet_truck_features.shape)\n",
        "internet_truck_result = model.predict(internet_truck_features)[0][0]\n",
        "\n",
        "print('internet_truck.png : {:0.2f}% chance of truck'.format(internet_truck_result * 100))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_MmTH5qEuedP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}