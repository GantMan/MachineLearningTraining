{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Truck Identifier - From Scratch",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GantMan/MachineLearningTraining/blob/master/Truck_Identifier_From_Scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "bCwz7w48tcuK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let's make a model to train with Keras that identifies trucks.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "4VOJU0_IueWh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras import regularizers\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JA7b0_ZfxM9m",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We'll be using the [CIFAR-10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html).  The CIFAR-10 dataset consists of 60000 32x32 color images in 10 classes, with 6000 images per class, all labeled.  \n",
        "\n",
        "This fortunately comes with an existing training/testing split ready to go right in Keras!  Thanks [pre-existing Keras datasets](https://keras.io/datasets/)!"
      ]
    },
    {
      "metadata": {
        "id": "ZNhTAKIXwxrw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Load data set\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K6bI-UFIxxX2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**The dataset is labeled with the following 10 numerical outcomes.**\n",
        "\n",
        "0.   Airplane\n",
        "1.   Automobile\n",
        "2.   Bird\n",
        "3.   Cat\n",
        "4.   deer\n",
        "5.   dog\n",
        "6.   frog\n",
        "7.   horse\n",
        "8.   ship\n",
        "9.   truck\n"
      ]
    },
    {
      "metadata": {
        "id": "qGpTZ6p_Wjco",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def visualize_classes():\n",
        "  graphic = []\n",
        "  for i in range(0, 10):\n",
        "      img_batch = x_train[y_train.flatten() == i][0:10] # 10 examples of each class\n",
        "      combo = np.concatenate(img_batch, axis = 0) # combine into an image\n",
        "      graphic.append(combo)\n",
        "  plt.figure(figsize=(12,24))\n",
        "  plt.axis('off')\n",
        "  plt.imshow(np.concatenate(graphic, axis = 1))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Vq-qxj3WWm6z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "visualize_classes()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "d3Vi6ZXv8v3b",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "We use a bit of boolean broadcasting to convert the numeric items to booleans.  We'll set truch to `true`, and all others to `false`.\n"
      ]
    },
    {
      "metadata": {
        "id": "FOy0xJS-vKyH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# adjust it so instead it sets all trucks to true and everything else to false\n",
        "# broadcast boolean logic througout dataset\n",
        "y_train = y_train == 9\n",
        "y_test = y_test == 9"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8VuSYK0Cvd23",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# prepare x to be normalized (between 0 and 1)\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xtN6W7pKvjNQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(\n",
        "    Conv2D(\n",
        "        32,\n",
        "        (3, 3),\n",
        "        padding='same',\n",
        "        input_shape=(32, 32, 3),\n",
        "        activation=\"relu\"\n",
        "    )\n",
        ")\n",
        "model.add(Conv2D(32, (3, 3), activation=\"relu\"))\n",
        "model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.25))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mpfd_e5SZU8i",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![pool after conv](https://pbs.twimg.com/media/DwCNkbIW0AENQy6.jpg =400x)"
      ]
    },
    {
      "metadata": {
        "id": "QqJx3xMfvoJU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# second grouping\n",
        "model.add(\n",
        "    Conv2D(64, (3, 3), padding='same', activation=\"relu\")\n",
        ")\n",
        "model.add(Conv2D(64, (3, 3), activation=\"relu\"))\n",
        "model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.25))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZMe2uMJ0V0WS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Adding L2 Regularization\n",
        "\n",
        "Regularization helps values that go too small, or too big for your computer from ruining everything.  Exploding and vanishing gradients, even if they don't crash your machine, can slow things downt o a crawl.   Regularization helps!   L2 is the most popular, unless you're looking to significantly remove useless inputs.  In those cases the more agressive L1 regularization would work."
      ]
    },
    {
      "metadata": {
        "id": "9EaqLJXrvsxP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Final dense layer\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation=\"relu\"))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation=\"sigmoid\", kernel_regularizer=regularizers.l2(0.01)))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Y1q_1c9rvyCO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    loss=\"binary_crossentropy\",\n",
        "    optimizer=\"adam\",\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6wVRoZIwUy4f",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Training with that GPU goodness\n",
        "\n",
        "![GPU yum](https://pbs.twimg.com/media/DrdQ4MIXgAIgIAG.jpg)\n",
        "\n",
        "To train we call `fit` on the model and we wait.  An epoch on a fast CPU is around 5 minutes."
      ]
    },
    {
      "metadata": {
        "id": "oI62QiCiullJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    batch_size=32,\n",
        "    epochs=3,\n",
        "    validation_data=(x_test, y_test),\n",
        "    shuffle=True\n",
        ")\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5q4YEIzBuwGl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.save(\"scratch_truck_model.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JVJnNPJ75J5B",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "At any time we can load this saved model.  We would import `load_model` from `keras.models` and call that with our model file 'scratch_truck_model.h5'"
      ]
    },
    {
      "metadata": {
        "id": "vF5latbr1jLB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.preprocessing import image\n",
        "from pathlib import Path\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EZdRj1yF5Cf7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**We'll try showing our model the following 2 images:**\n",
        "\n",
        "This 32x32x3 truck -  ![truck](https://www.cs.toronto.edu/~kriz/cifar-10-sample/truck2.png) as `truck.png`\n",
        "\n",
        "And this 32x32x3 bird -  ![bird](https://www.cs.toronto.edu/~kriz/cifar-10-sample/bird8.png) as `not_truck.png`"
      ]
    },
    {
      "metadata": {
        "id": "jEThoLtl5sWo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import urllib.request\n",
        "\n",
        "urllib.request.urlretrieve (\"https://www.cs.toronto.edu/~kriz/cifar-10-sample/truck2.png\", \"truck.png\")\n",
        "urllib.request.urlretrieve (\"https://www.cs.toronto.edu/~kriz/cifar-10-sample/bird8.png\", \"not_truck.png\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BI7BtHsv88ux",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![wut cifar image](https://pbs.twimg.com/media/DwCQutKW0AAUKqk.jpg =400x)"
      ]
    },
    {
      "metadata": {
        "id": "-2vUTzuH5vKo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for f in sorted(Path(\".\").glob(\"*.png\")):\n",
        "    # Load an image file to test\n",
        "    image_to_test = image.load_img(\n",
        "        str(f),\n",
        "        target_size=(32, 32)\n",
        "    )\n",
        "\n",
        "    # Convert the image data to a numpy array\n",
        "    # suitable for Keras\n",
        "    image_to_test = image.img_to_array(image_to_test)\n",
        "    # normalize to a 0 to 1 value\n",
        "    image_to_test /= 255\n",
        "\n",
        "    # Add a fourth dimension to the image since\n",
        "    # Keras expects a list of images\n",
        "    list_of_images = np.expand_dims(\n",
        "        image_to_test,\n",
        "        axis=0\n",
        "    )\n",
        "    # Make a prediction using the truck model\n",
        "    results = model.predict(list_of_images)\n",
        "\n",
        "    # Since we only passed in one test image,\n",
        "    # we can just check the first result directly.\n",
        "    image_likelihood = results[0][0]\n",
        "\n",
        "    # The result will be a number from 0.0 to 1.0\n",
        "    # representing the likelihood that this\n",
        "    # image is a truck.\n",
        "    if image_likelihood > 0.5:\n",
        "        print(f\"{f} is a truck! ({image_likelihood:.2f})\")\n",
        "    else:\n",
        "        print(f\"{f} is NOT a truck! ({image_likelihood:.2f})\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zNkzUGVmZuCx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![confusion matrix](https://www.dataschool.io/content/images/2015/01/confusion_matrix2.png)"
      ]
    },
    {
      "metadata": {
        "id": "bQREHXtWDj2e",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "predictions = model.predict(x_test, batch_size=32, verbose=1)\n",
        "# If the model is more than 50% sure the object is a truck, call it a truck.\n",
        "# Otherwise, call it \"not a truck\" via boolean\n",
        "predictions = predictions > 0.5\n",
        "\n",
        "# Calculate Precision and Recall for each class\n",
        "report = classification_report(y_test, predictions)\n",
        "print(report)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "x3eNA6w3bCGM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "F-score (F1 score) is the harmonic mean of precision and recall:\n",
        "\n",
        ">$F1=2*\\frac{precision*recall}{precision+recall}$\n",
        "\n",
        "Basically a way for us to give some kind of combo-score to their trade-offs."
      ]
    },
    {
      "metadata": {
        "id": "CKIAi9JzGwHt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "pip install tensorflowjs\n",
        "tensorflowjs_converter --input_format keras \\\n",
        "                       ./scratch_truck_model.h5 \\\n",
        "                       ./tfjs_target_dir"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nebXXPB7JEf7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!ls ./tfjs_target_dir"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ej3I_qUSW1jG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![me](https://pbs.twimg.com/media/DvFA7pNV4AAiW49.jpg =400x)"
      ]
    },
    {
      "metadata": {
        "id": "ji3G-uzFW4ot",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}